{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "JT1r0UBm5gFL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "212a1e6e-c3a2-4981-ddd6-d3a475b7a5dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "f9ODnpNZx351"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WYMAItf04zVN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import accelerate\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LHZTcz9_FvWc",
        "outputId": "e5aee34e-98f5-4f0d-bf8c-87e52d588cbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading pre-trained DistilBERT...\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eGCThslI47HQ",
        "outputId": "833bf7ad-5a63-4ce1-d6ce-2ddb924ed95f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the dataset"
      ],
      "metadata": {
        "id": "EIjC1qfY6QR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples, tokenizer, device, max_length=512):\n",
        "    \"\"\"\n",
        "    Tokenizes the text data and prepares it for model input.\n",
        "\n",
        "    Args:\n",
        "        examples: A batch of text samples from the dataset.\n",
        "        tokenizer: The tokenizer instance for the model.\n",
        "        device: The device (CPU/GPU) where tensors will be moved.\n",
        "        max_length: Maximum sequence length for padding/truncation.\n",
        "\n",
        "    Returns:\n",
        "        Encoded tensors moved to the specified device.\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    encoded = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
        "\n",
        "    # Ensure tensors are on the same device\n",
        "    for key in encoded:\n",
        "        encoded[key] = torch.tensor(encoded[key]).to(device)  # Explicitly move to GPU\n",
        "\n",
        "    return encoded\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Sample 5000 rows from the training and test sets first\n",
        "train_sample = dataset[\"train\"].shuffle(seed=40).select(range(5000))  # Select first 1000 from shuffled dataset\n",
        "test_sample = dataset[\"test\"].shuffle(seed=40).select(range(5000))\n",
        "\n",
        "# Preprocess the sampled dataset\n",
        "print(\"Preprocessing sampled dataset...\")\n",
        "tokenized_train = train_sample.map(lambda x: preprocess_data(x, tokenizer, device), batched=True)\n",
        "tokenized_test = test_sample.map(lambda x: preprocess_data(x, tokenizer, device), batched=True)\n",
        "\n",
        "# Rename and set format\n",
        "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
        "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# Now you have tokenized, sampled datasets\n",
        "train_dataset = tokenized_train\n",
        "test_dataset = tokenized_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eV1-Xntl5_R7",
        "outputId": "26269c13-84e1-4047-a657-c7e5bd5845ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Preprocessing sampled dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Computes classification metrics (accuracy, precision, recall, F1-score)\n",
        "    for the model's predictions.\n",
        "\n",
        "    Args:\n",
        "        pred: Predictions output by the model during evaluation.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing calculated metrics.\n",
        "    \"\"\"\n",
        "    logits, labels = pred\n",
        "    preds = torch.argmax(torch.tensor(logits), axis=1)\n",
        "    #preds = torch.argmax(logits, axis=1) # No need to convert to tensor, already a tensor\n",
        "    # Move both predictions and labels to CPU\n",
        "    preds = preds.cpu().numpy()\n",
        "    #labels = labels.cpu().numpy()\n",
        "    labels = labels.cpu().numpy() if isinstance(labels, torch.Tensor) else labels\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Return a dictionary containing the computed metrics\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1} # Added return statement\n"
      ],
      "metadata": {
        "id": "4nr44Uk-MefJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Trainer and TrainingArguments"
      ],
      "metadata": {
        "id": "Pv697Fqj9zOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,  # Ensure best model is loaded\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True,  # Enable mixed precision for faster training on compatible GPUs\n",
        "    report_to=\"none\",\n",
        "    no_cuda=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TlgXmjik9jTt",
        "outputId": "f8e5c4ab-7e82-455c-cd68-a51dcec04021"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-14-d17b183b5851>:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "xVPQhQUQ-OEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZfVJzqIeCQC1",
        "outputId": "c81c4608-4426-4fe0-8ddc-3b5c696b60aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training the model...\")\n",
        "# Verify that the model is on the GPU\n",
        "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "gRxH_cYA-BDP",
        "outputId": "7b011a47-76e2-4c48-f026-f6d726951e14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Model is on device: cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [939/939 04:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.253806</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.876201</td>\n",
              "      <td>0.915261</td>\n",
              "      <td>0.895305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.280100</td>\n",
              "      <td>0.362496</td>\n",
              "      <td>0.889000</td>\n",
              "      <td>0.839831</td>\n",
              "      <td>0.960241</td>\n",
              "      <td>0.896009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.280100</td>\n",
              "      <td>0.357314</td>\n",
              "      <td>0.916400</td>\n",
              "      <td>0.920114</td>\n",
              "      <td>0.911245</td>\n",
              "      <td>0.915658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=939, training_loss=0.19960033347685371, metrics={'train_runtime': 289.4679, 'train_samples_per_second': 51.819, 'train_steps_per_second': 3.244, 'total_flos': 1987010979840000.0, 'train_loss': 0.19960033347685371, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(\"Evaluating the model...\")\n",
        "results = trainer.evaluate()\n",
        "print(f\"Results: {results}\")"
      ],
      "metadata": {
        "id": "NRVnK6Yr-TFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "d9d6a1ef-3314-4d62-d3e3-e49aae78e9db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [313/313 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: {'eval_loss': 0.3573143184185028, 'eval_accuracy': 0.9164, 'eval_precision': 0.9201135442011354, 'eval_recall': 0.9112449799196787, 'eval_f1': 0.9156577885391445, 'eval_runtime': 20.5768, 'eval_samples_per_second': 242.992, 'eval_steps_per_second': 15.211, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./distilbert-imdb-classifier\")\n",
        "tokenizer.save_pretrained(\"./distilbert-imdb-classifier\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JJW_KkymLPMT",
        "outputId": "1989ecac-f017-4538-9b36-2389f94b87c5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./distilbert-imdb-classifier/tokenizer_config.json',\n",
              " './distilbert-imdb-classifier/special_tokens_map.json',\n",
              " './distilbert-imdb-classifier/vocab.txt',\n",
              " './distilbert-imdb-classifier/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "WYAD2thjQpsX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = \"\" # Add OpenAI Key here"
      ],
      "metadata": {
        "id": "E6EvKkXoQqK4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDB dataset and sample 1000 rows\n",
        "#dataset = load_dataset(\"imdb\")\n",
        "eval_data = dataset[\"test\"].shuffle(seed=40).select(range(5000))"
      ],
      "metadata": {
        "id": "pyqkbj7IQyY9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt template\n",
        "def create_prompt(review_text):\n",
        "    \"\"\"\n",
        "    Creates a classification prompt for GPT-3.5.\n",
        "\n",
        "    Args:\n",
        "        review_text: The text of the movie review.\n",
        "\n",
        "    Returns:\n",
        "        A formatted string prompt for GPT-3.5.\n",
        "    \"\"\"\n",
        "    return f\"\"\"\n",
        "    The following text is a movie review. Classify it as either \"Positive\" or \"Negative\" based on the sentiment expressed in the review.\n",
        "    Review: \"{review_text}\"\n",
        "    Sentiment:\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "OTjpGwLdQ09O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loop through the evaluation dataset and collect responses"
      ],
      "metadata": {
        "id": "kgQKlz5nQ_4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_openai(review_text):\n",
        "    \"\"\"\n",
        "    Sends a review to GPT-3.5 for sentiment classification.\n",
        "\n",
        "    Args:\n",
        "        review_text: The text of the movie review.\n",
        "\n",
        "    Returns:\n",
        "        Predicted sentiment label as a string.\n",
        "    \"\"\"\n",
        "    prompt = create_prompt(review_text)\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(  # Use ChatCompletion\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=10,\n",
        "            temperature=0\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()  # Access content differently\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "EdP4kZjxQ4AQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for row in eval_data:\n",
        "    review_text = row[\"text\"]\n",
        "    true_label = \"Positive\" if row[\"label\"] == 1 else \"Negative\"\n",
        "\n",
        "    # Get prediction from OpenAI\n",
        "    prediction = query_openai(review_text)\n",
        "\n",
        "    # Append results\n",
        "    true_labels.append(true_label)\n",
        "    predicted_labels.append(prediction)\n",
        "\n",
        "    # Optional: Add delay to avoid hitting API rate limits\n",
        "    time.sleep(1)\n",
        ""
      ],
      "metadata": {
        "id": "Mhs3JsHjLGMt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time"
      ],
      "metadata": {
        "id": "jdvLbsbuQotF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [1 if label == \"Positive\" else 0 for label in true_labels]\n",
        "predicted_labels = [1 if label == \"Positive\" else 0 for label in predicted_labels]\n",
        "\n",
        "# Calculate metrics with average='binary'\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, pos_label=1, average='binary')\n",
        "recall = recall_score(true_labels, predicted_labels, pos_label=1, average='binary')\n",
        "f1 = f1_score(true_labels, predicted_labels, pos_label=1, average='binary')\n",
        "\n",
        "# Evaluate performance\n",
        "#accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "#precision = precision_score(true_labels, predicted_labels, pos_label=\"Positive\", average='micro')  # Changed to 'micro'\n",
        "#recall = recall_score(true_labels, predicted_labels, pos_label=\"Positive\", average='micro')  # Changed to 'micro'\n",
        "#f1 = f1_score(true_labels, predicted_labels, pos_label=\"Positive\", average='micro')  # Changed to 'micro'\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df = pd.DataFrame({\n",
        "    \"Review\": [row[\"text\"] for row in eval_data],\n",
        "    \"True Label\": true_labels,\n",
        "    \"Predicted Label\": predicted_labels\n",
        "})\n",
        "results_df.to_csv(\"imdb_openai_evaluation_results.csv\", index=False)\n",
        "print(\"Results saved to imdb_openai_evaluation_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WDxjJq0mQcZr",
        "outputId": "a57b26da-fc1f-4508-e06b-7d8532d9694c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Accuracy: 0.9180\n",
            "Precision: 0.9622\n",
            "Recall: 0.8605\n",
            "F1 Score: 0.9085\n",
            "Results saved to imdb_openai_evaluation_results.csv\n"
          ]
        }
      ]
    }
  ]
}